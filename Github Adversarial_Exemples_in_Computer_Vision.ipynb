{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT8fKGGYlhJx"
      },
      "source": [
        "# **Fooling AI image classifers**\n",
        "#### by Outmani Ossama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y8B1MBVh-rh"
      },
      "source": [
        "# A. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. download essential files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def download_from_link(link,filename):\n",
        "  # Download the image\n",
        "  response = requests.get(link)\n",
        "\n",
        "  # Check for successful download\n",
        "  if response.status_code == 200:\n",
        "    print(response.headers['Content-Type'])\n",
        "    with open(filename, 'wb') as f:\n",
        "      f.write(response.content)\n",
        "  else:\n",
        "      print(f\"Error downloading {filename}: {response.status_code}\")\n",
        "\n",
        "download_from_link(\"https://raw.githubusercontent.com/nexossama/Adversarial-Exemples-in-Computer-Vision/main/Cat.jpg\",\"Cat.jpg\")\n",
        "download_from_link(\"https://raw.githubusercontent.com/nexossama/Adversarial-Exemples-in-Computer-Vision/main/imageNet.json\",\"imageNet.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIlLYJodteZ0"
      },
      "source": [
        "## 1. Getting used with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yogT-qTqmG7p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TmMvgVpLYNg",
        "outputId": "0eb49a78-e040-4081-f83d-54c03155f84f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdOeB22eyCPF"
      },
      "source": [
        "###  1.a. load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne8Cx2UMyB4w"
      },
      "outputs": [],
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,weights='imagenet')\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "# function to get the predicted label\n",
        "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jIS0-LzykCT"
      },
      "source": [
        "###  1.b. get the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNHv5jNqvMTk"
      },
      "outputs": [],
      "source": [
        "# comment this cell if you are runnning this notebook locally\n",
        "from google.colab import files\n",
        "\n",
        "def read_image(image_path=None):\n",
        "  if image_path is None:\n",
        "    uploaded = files.upload()\n",
        "    image_path=list(uploaded.keys())[0]\n",
        "  image_raw = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_image(image_raw)\n",
        "  return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJXrLTiNy0_V"
      },
      "outputs": [],
      "source": [
        "# comment this cell if you are runnning this notebook in Collab\n",
        "def read_image(image_path=None):\n",
        "  if image_path is None:\n",
        "    image_path=input(\"Please enter the image path\")\n",
        "  image_raw = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_image(image_raw)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3pyT4bOzBOu"
      },
      "outputs": [],
      "source": [
        "# default image\n",
        "image = read_image(image_path=\"Cat.jpg\")\n",
        "\n",
        "# to upload your own image\n",
        "# image = read_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuiB5pd815un"
      },
      "source": [
        "###  1.c. Preprocess the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THgtjKwIzTnX"
      },
      "outputs": [],
      "source": [
        "#used only to preprocess the original image\n",
        "def preprocess_org(photo):\n",
        "  resized_image=tf.image.resize(photo,(224,224))\n",
        "  resized_image=resized_image[None,...]\n",
        "  return resized_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr-jT5dj2Mga"
      },
      "outputs": [],
      "source": [
        "#preprecess the image to be compatible with the model\n",
        "def preprocess(photo):\n",
        "  resized_image=tf.image.resize(photo,(224,224))\n",
        "  resized_image=resized_image[None,...]\n",
        "  preprocessed_image = tf.keras.applications.mobilenet_v2.preprocess_input(resized_image)\n",
        "  return preprocessed_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNJiUcvm2nrZ"
      },
      "outputs": [],
      "source": [
        "preprocessed_image=preprocess(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_sdZ7dR2sxX"
      },
      "source": [
        "###  1.d. Predict the label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aaji1nKh2xxg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "#return one_hot encoding corresponding to given label\n",
        "def one_hot_from_label(label,size=1000):\n",
        "  with open(\"imageNet.json\",\"r\") as f:\n",
        "    labels_dict=json.load(f)\n",
        "  index=labels_dict[label]\n",
        "  label_array = tf.one_hot(index, size)\n",
        "  label_array = tf.reshape(label_array, (1,size))\n",
        "\n",
        "  return label_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFet_8sr3fT8"
      },
      "outputs": [],
      "source": [
        "#probilities of each label for the given image\n",
        "def mobilenet_v2_predict(image):\n",
        "  preprocessed_image=preprocess(image)\n",
        "  predictions=pretrained_model.predict(preprocessed_image,verbose=\"0\")\n",
        "  decoded_prediction=decode_predictions(predictions,top=1)[0]\n",
        "\n",
        "  loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "  label=decoded_prediction[0][1]\n",
        "  one_hot_label=one_hot_from_label(label)\n",
        "  loss = loss_object(one_hot_label, predictions)\n",
        "  return {\"predictions\" : predictions ,\"loss\" : loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GIF2dw944Sd"
      },
      "outputs": [],
      "source": [
        "# get label and confidence level for an image\n",
        "def get_class(probabilities):\n",
        "  _ , label , confidence = decode_predictions(probabilities,top=1)[0][0]\n",
        "  return {\"label\":label,\"confidence\":confidence}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"Cat.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "kVlBujun36lu",
        "outputId": "eb145c6b-798f-48c7-eb43-66f1e01f71b4"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (3, 3)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "#display given image along with prediction information\n",
        "def display_prediction(image,xlabel=None):\n",
        "    plt.figure()\n",
        "    img_ajusted=np.asarray(preprocess_org(image))[0]\n",
        "    plt.imshow(img_ajusted/255)\n",
        "    label,confidence=get_class(mobilenet_v2_predict(image)[\"predictions\"]).values()\n",
        "    plt.title(f\"{confidence*100:.2f}% {label}\",fontsize=\"15\")\n",
        "    if xlabel is not None:\n",
        "        plt.xlabel(xlabel,fontsize=\"13\")\n",
        "\n",
        "display_prediction(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5I7DU7-tw0"
      },
      "source": [
        "## 2. Building Adversarial exemples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWEzJO2D-yKQ"
      },
      "outputs": [],
      "source": [
        "#generate noise for a given image\n",
        "def generate_adversarial_noise(image,type=\"sign\"):\n",
        "    \"\"\"\n",
        "    type : \"sign\" or \"norm\" \n",
        "          where \"sign\" defines the standard FGSM technique and \"norm\" stands for the normalized version of FGSM\n",
        "    \"\"\"\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "    label=get_class(mobilenet_v2_predict(image)[\"predictions\"])[\"label\"]\n",
        "    one_hot_label=one_hot_from_label(label)\n",
        "    image=preprocess(image)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(image)\n",
        "      predictions = pretrained_model(image)\n",
        "      loss = loss_object(one_hot_label, predictions)\n",
        "    gradient = tape.gradient(loss, image)    # Get the gradients of the loss with respect to the input image.\n",
        "\n",
        "    if type==\"sign\": # Get the sign of the gradients to create the perturbation\n",
        "      signed_grad = tf.sign(gradient)  \n",
        "      return signed_grad\n",
        "    \n",
        "    elif type==\"norm\": # Get the normalize version of the gradients to create the perturbation\n",
        "      max_grad = tf.reduce_max(tf.math.abs(gradient)) \n",
        "      return gradient/max_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6XyrED5DaN-"
      },
      "source": [
        "## 3. Visualising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVMQCx9HDgZF"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (12, 8)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "#display before and after and noise of a given image after FGSM\n",
        "def display_exemples(image,epsilon=[0.07],type=\"sign\"):\n",
        "  \"\"\"\n",
        "    epsilon : list\n",
        "      list of all epsilons to try at once\n",
        "     \n",
        "    type : \"sign\" or \"norm\" \n",
        "          where \"sign\" defines the standard FGSM technique and \"norm\" stands for the normalized version of FGSM\n",
        "  \"\"\"\n",
        "  i=1\n",
        "  for e in epsilon :\n",
        "    plt.figure(i)\n",
        "    plt.subplot(231)\n",
        "    noise=generate_adversarial_noise(image,type=type)\n",
        "    img_ajusted=np.asarray(preprocess_org(image)).reshape(224,224,3)\n",
        "    plt.imshow(img_ajusted/255)\n",
        "    prediction=mobilenet_v2_predict(image)\n",
        "    label,confidence=get_class(mobilenet_v2_predict(image)[\"predictions\"]).values()\n",
        "    plt.title(f\"{confidence*100:.2f}% {label}\")\n",
        "    label=get_class(mobilenet_v2_predict(image)[\"predictions\"])[\"label\"]\n",
        "\n",
        "\n",
        "    plt.subplot(233)\n",
        "    adv_image=preprocess_org(image)+e*noise\n",
        "    adv_image=tf.clip_by_value(adv_image,0,255)\n",
        "    prediction_couple=mobilenet_v2_predict(adv_image[0])[\"predictions\"]\n",
        "    label,confidence=get_class(prediction_couple).values()\n",
        "    plt.title(f\"{confidence*100:.2f}% {label}\")\n",
        "    adv_ajusted=adv_image[0]\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0)\n",
        "    one_hot_label=one_hot_from_label(label)\n",
        "    loss = loss_object(one_hot_label, prediction_couple)\n",
        "    \n",
        "    plt.imshow(adv_ajusted/tf.reduce_max(tf.math.abs(adv_ajusted)))\n",
        "    # plt.xlabel(f\"type : {type} , loss : {loss}\")\n",
        "    \n",
        "    plt.subplot(232)\n",
        "    plt.title(f\"ϵ={e}\")\n",
        "    plt.xlabel(f\"type : {type} , loss : {loss}\")\n",
        "\n",
        "    plt.imshow(np.asarray(noise*0.5+0.5).reshape(224,224,3))\n",
        "\n",
        "    i+=1\n",
        "\n",
        "\n",
        "display_exemples(image,[0.5,1,100],\"sign\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqPaEPMiHNC"
      },
      "source": [
        "# B. Paper Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfQ6ILX0iL_f"
      },
      "outputs": [],
      "source": [
        "img=read_image(\"cat6.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFQPqI67G1Gh"
      },
      "source": [
        "## Experiment 1 : FGSM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVibQasG08p"
      },
      "source": [
        "applying FGSM to an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "WIfG1oEiG00j",
        "outputId": "15a29520-490d-4dcb-e8c3-d5ffc44b1862"
      },
      "outputs": [],
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 8)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "display_exemples(img,epsilon=[0.5],type=\"sign\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHaeWEKfHz2t"
      },
      "source": [
        "## Experiment 2 : FGSM with multiple epsilons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lqvdMjjMz4FP",
        "outputId": "52fc9e00-d1be-4a9d-c077-5e3889eec3a5"
      },
      "outputs": [],
      "source": [
        "display_exemples(img,epsilon=[20,50],type=\"sign\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmET0hKl0OOy"
      },
      "source": [
        "## Experiment 3 : optimizing FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7tmFhdUGKEBZ",
        "outputId": "c6f0a21d-3c2d-4ffd-de6e-9ef1faee28f4"
      },
      "outputs": [],
      "source": [
        "display_exemples(img,epsilon=[0.5,5,20,50,100,200],type=\"norm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4 : Testing on Real-life images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Original printed and photographed image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"assests/original.jpg\")\n",
        "display_prediction(image,xlabel=\"original\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adversarial example generated with FGSM with Ɛ=0.5 printed and photographed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"assests/sign0.5.jpg\")\n",
        "display_prediction(image,xlabel=\"type='sign', Ɛ=0.5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adversarial example generated with FGSM with Ɛ=1 printed and photographed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"assests/sign1.jpg\")\n",
        "display_prediction(image,xlabel=\"type='sign', Ɛ=1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adversarial example generated with FGSM with Ɛ=10 printed and photographed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"assests/sign10.jpg\")\n",
        "display_prediction(image,xlabel=\"type='sign', Ɛ=10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adversarial example generated with Normalized version of FGSM with Ɛ=10 printed and photographed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"assests/norm10.jpg\")\n",
        "display_prediction(image,xlabel=\"type='norm', Ɛ=10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adversarial example generated with Normalized version of FGSM with Ɛ=50 printed and photographed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image=read_image(\"assests/norm50.jpg\")\n",
        "display_prediction(image,xlabel=\"type='norm', Ɛ=50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# C. Generate and Download "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def download_adversarial_image(image_path,type=\"sign\",epsilon=10,filename=None):\n",
        "    \"\"\"\n",
        "    image_path : str\n",
        "        path to the source image\n",
        "    \n",
        "    type : \"sign\" or \"norm\" \n",
        "        where \"sign\" defines the standard FGSM technique and \"norm\" stands for the normalized version of FGSM\n",
        "    \n",
        "    epsilon : float\n",
        "      list of all epsilons to try at once\n",
        "      \n",
        "    filename : str\n",
        "      name of the generated image , if none ,it will be same as original\n",
        "  \"\"\"\n",
        "    image=read_image(image_path)\n",
        "    noise=generate_adversarial_noise(image,type=type)\n",
        "    adv_image=preprocess_org(image)+epsilon*noise\n",
        "    adv_image=tf.clip_by_value(adv_image,0,255)\n",
        "    im = tf.image.resize(adv_image, (image.shape[0], image.shape[1]))\n",
        "    if filename is None :\n",
        "        tf.keras.preprocessing.image.save_img(os.path.basename(image_path),im[0])\n",
        "    else :\n",
        "        tf.keras.preprocessing.image.save_img(filename,im[0])\n",
        "    print(\"done\")\n",
        "# files.download(\"proceedimage.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_adversarial_image(\"Cat.jpg\",\"sign\",filename=\"generatedCat.jpg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5Y8B1MBVh-rh",
        "sdOeB22eyCPF",
        "7jIS0-LzykCT",
        "PuiB5pd815un",
        "j6XyrED5DaN-",
        "bFQPqI67G1Gh",
        "VHaeWEKfHz2t",
        "bmET0hKl0OOy"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
